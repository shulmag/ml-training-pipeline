{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Merge Data Files\nCreated by [Author name removed] on 2024-12-06.  \nLast edited by [Name removed] on 2024-12-06.\n\nThis notebook is used to merge two pickle files where each pickle file represents a pandas DataFrame.\n\nTo run the notebook, use Python 3.10 (Python 3.12 does not work), and\n- on linux: use `ficc_python/requirements_py310_linux_jupyter.txt`\n- on mac: use `ficc_python/requirements_py310_mac_jupyter.txt`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "file1_path = '~/ficc/ficc_python/notebooks/merge_data_files/files/processed_data_yield_spread_with_similar_trades.pkl'\nfile2_path = '~/ficc/ficc_python/notebooks/compare_datasets/files/new_data.pkl'\nfile3_path = '~/ficc/ficc_python/notebooks/compare_datasets/files/new_data_2024-11-01_2024-12-05.pkl'\noutput_file_path = '~/ficc/ficc_python/notebooks/merge_data_files/files/processed_data_yield_spread_with_similar_trades_v2.pkl'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATETIME_COLUMN_NAME = 'trade_datetime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_DROP = ['sp_stand_alone', 'moodys_long']    # columns that are no longer used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_OF_DAY_TIME = '00:00:00'\n",
    "END_OF_DAY_TIME = '23:59:59'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_between_datetimes(file_path: str, \n",
    "                             start_datetime: str = None, \n",
    "                             end_datetime: str = None, \n",
    "                             datetime_column_name: str = DATETIME_COLUMN_NAME) -> pd.DataFrame:\n",
    "    if start_datetime is None and end_datetime is None: warnings.warn('Both `start_datetime` and `end_datetime` are `None`, and so all rows returned')\n",
    "    df = pd.read_pickle(file_path)\n",
    "    if datetime_column_name not in df.columns: raise ValueError(f'Column `{datetime_column_name}` not found in the DataFrame from {file_path}')\n",
    "    if start_datetime is not None: df = df[df[datetime_column_name] >= start_datetime]\n",
    "    if end_datetime is not None: df = df[df[datetime_column_name] <= end_datetime]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_to_june_30 = get_df_between_datetimes(file1_path, end_datetime=f'2024-06-30 {END_OF_DAY_TIME}')\n",
    "df2_from_july_1 = get_df_between_datetimes(file2_path, start_datetime=f'2024-07-01 {START_OF_DAY_TIME}')\n",
    "df3 = get_df_between_datetimes(file3_path)\n",
    "combined_df = pd.concat([df1_to_june_30, df2_from_july_1, df3])\n",
    "combined_df = combined_df.sort_values(by='trade_datetime', ascending=False)\n",
    "combined_df = combined_df.drop(columns=COLUMNS_TO_DROP, errors='ignore')    # will ignore the error when any of the columns in  `COLUMNS_TO_DROP` do not exist in `combined_df`\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['trade_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Earliest trade datetime: {combined_df[\"trade_datetime\"].min()}')\n",
    "print(f'Latest trade datetime: {combined_df[\"trade_datetime\"].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert combined_df['rtrs_control_number'].is_unique, f'Duplicate RTRS control numbers present: {combined_df[\"rtrs_control_number\"][combined_df[\"rtrs_control_number\"].duplicated()].unique()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR_MONTH_DAY = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekdays_between_dates(start_date: str, end_date: str) -> list:\n",
    "    start_date = datetime.strptime(start_date, YEAR_MONTH_DAY)\n",
    "    end_date = datetime.strptime(end_date, YEAR_MONTH_DAY)\n",
    "    if start_date > end_date: raise ValueError(f'Start date: {start_date} must be before or equal to the end date: {end_date}')\n",
    "    \n",
    "    weekdays = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        if current_date.weekday() < 5:    # weekdays are Monday (0) to Friday (4)\n",
    "            weekdays.append(current_date.strftime(YEAR_MONTH_DAY))\n",
    "        current_date += timedelta(days=1)\n",
    "    return weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trade_dates = [numpy_datetime.astype('datetime64[ms]').astype(datetime).strftime(YEAR_MONTH_DAY) for numpy_datetime in combined_df['trade_date'].unique()]\n",
    "earliest_trade_date = combined_df['trade_date'].min().strftime(YEAR_MONTH_DAY)\n",
    "latest_trade_date = combined_df['trade_date'].max().strftime(YEAR_MONTH_DAY)\n",
    "print(f'The following dates are missing from the combined dataframe. These should be holidays.\\n{sorted(set(get_weekdays_between_dates(earliest_trade_date, latest_trade_date)) - set(unique_trade_dates))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_pickle(output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}