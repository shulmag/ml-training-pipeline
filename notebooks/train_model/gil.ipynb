{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rtrs_control_number</th>\n",
       "      <th>cusip</th>\n",
       "      <th>yield</th>\n",
       "      <th>is_callable</th>\n",
       "      <th>refund_date</th>\n",
       "      <th>accrual_date</th>\n",
       "      <th>dated_date</th>\n",
       "      <th>next_sink_date</th>\n",
       "      <th>coupon</th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>...</th>\n",
       "      <th>D_min_ago_ago</th>\n",
       "      <th>D_min_ago_qdiff</th>\n",
       "      <th>P_min_ago_ys</th>\n",
       "      <th>P_min_ago_ttypes</th>\n",
       "      <th>P_min_ago_ago</th>\n",
       "      <th>P_min_ago_qdiff</th>\n",
       "      <th>S_min_ago_ys</th>\n",
       "      <th>S_min_ago_ttypes</th>\n",
       "      <th>S_min_ago_ago</th>\n",
       "      <th>S_min_ago_qdiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024091815398500</td>\n",
       "      <td>53340CBH3</td>\n",
       "      <td>316.9</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>...</td>\n",
       "      <td>5.895651</td>\n",
       "      <td>5.352185</td>\n",
       "      <td>20.708705</td>\n",
       "      <td>PP</td>\n",
       "      <td>5.895351</td>\n",
       "      <td>5.352185</td>\n",
       "      <td>22.930882</td>\n",
       "      <td>SP</td>\n",
       "      <td>4.527656</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024091815398600</td>\n",
       "      <td>914318T59</td>\n",
       "      <td>373.9</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2046-04-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.415841</td>\n",
       "      <td>5.000005</td>\n",
       "      <td>66.617513</td>\n",
       "      <td>SP</td>\n",
       "      <td>4.414689</td>\n",
       "      <td>5.000005</td>\n",
       "      <td>66.617513</td>\n",
       "      <td>SP</td>\n",
       "      <td>4.414689</td>\n",
       "      <td>5.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024091815398700</td>\n",
       "      <td>51771FAU0</td>\n",
       "      <td>418.4</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>2044-07-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>...</td>\n",
       "      <td>4.057856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.883110</td>\n",
       "      <td>PP</td>\n",
       "      <td>5.720730</td>\n",
       "      <td>4.176120</td>\n",
       "      <td>140.174509</td>\n",
       "      <td>SP</td>\n",
       "      <td>4.057856</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024091815233000</td>\n",
       "      <td>850752SL1</td>\n",
       "      <td>301.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>...</td>\n",
       "      <td>4.078566</td>\n",
       "      <td>0.023210</td>\n",
       "      <td>25.271729</td>\n",
       "      <td>DS</td>\n",
       "      <td>4.078566</td>\n",
       "      <td>0.023210</td>\n",
       "      <td>14.471729</td>\n",
       "      <td>SS</td>\n",
       "      <td>4.078566</td>\n",
       "      <td>0.023210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024091815233100</td>\n",
       "      <td>850752SL1</td>\n",
       "      <td>311.8</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>...</td>\n",
       "      <td>4.078566</td>\n",
       "      <td>0.023210</td>\n",
       "      <td>25.271729</td>\n",
       "      <td>DD</td>\n",
       "      <td>4.078566</td>\n",
       "      <td>0.023210</td>\n",
       "      <td>14.471729</td>\n",
       "      <td>SD</td>\n",
       "      <td>4.078566</td>\n",
       "      <td>0.023210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rtrs_control_number      cusip  yield  is_callable refund_date  \\\n",
       "0     2024091815398500  53340CBH3  316.9         True         NaT   \n",
       "1     2024091815398600  914318T59  373.9         True         NaT   \n",
       "2     2024091815398700  51771FAU0  418.4         True         NaT   \n",
       "3     2024091815233000  850752SL1  301.0         True         NaT   \n",
       "4     2024091815233100  850752SL1  311.8         True         NaT   \n",
       "\n",
       "  accrual_date dated_date next_sink_date  coupon delivery_date  ...  \\\n",
       "0   2023-04-12 2023-04-12            NaT     5.0    2023-04-12  ...   \n",
       "1   2020-04-01 2020-04-01     2046-04-01     5.0    2020-04-01  ...   \n",
       "2   2018-10-09 2018-10-09     2044-07-01     4.0    2018-10-09  ...   \n",
       "3   2019-03-28 2019-03-28            NaT     3.0    2019-03-28  ...   \n",
       "4   2019-03-28 2019-03-28            NaT     3.0    2019-03-28  ...   \n",
       "\n",
       "  D_min_ago_ago D_min_ago_qdiff P_min_ago_ys P_min_ago_ttypes  P_min_ago_ago  \\\n",
       "0      5.895651        5.352185    20.708705               PP       5.895351   \n",
       "1      4.415841        5.000005    66.617513               SP       4.414689   \n",
       "2      4.057856        0.000000    39.883110               PP       5.720730   \n",
       "3      4.078566        0.023210    25.271729               DS       4.078566   \n",
       "4      4.078566        0.023210    25.271729               DD       4.078566   \n",
       "\n",
       "   P_min_ago_qdiff  S_min_ago_ys  S_min_ago_ttypes  S_min_ago_ago  \\\n",
       "0         5.352185     22.930882                SP       4.527656   \n",
       "1         5.000005     66.617513                SP       4.414689   \n",
       "2         4.176120    140.174509                SP       4.057856   \n",
       "3         0.023210     14.471729                SS       4.078566   \n",
       "4         0.023210     14.471729                SD       4.078566   \n",
       "\n",
       "   S_min_ago_qdiff  \n",
       "0         0.000000  \n",
       "1         5.000005  \n",
       "2         0.000000  \n",
       "3         0.023210  \n",
       "4         0.023210  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_old = pd.read_pickle('/Users/gil/git/ficc_python/notebooks/train_model/gilmac_2024-09-18_2024-08-20_old_yield_spread_with_similar_trades.pkl')\n",
    "df_old.head()\n",
    "\n",
    "df_new = pd.read_pickle('/Users/gil/Downloads/2024-09-18_2024-08-20_processed_data_v3.pkl')\n",
    "df_new.head()\n",
    "\n",
    "# Merge on rtrs_control_number\n",
    "df_merged = pd.merge(\n",
    "    df_old, \n",
    "    df_new, \n",
    "    on='rtrs_control_number', \n",
    "    suffixes=('_old', '_new'),\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame shape: (951750, 279)\n",
      "Number of matching rtrs_control_numbers: 951750\n",
      "\n",
      "=== SIGNIFICANT ISSUE_AMOUNT DIFFERENCES ===\n",
      "Found 479391 SIGNIFICANT differences in issue_amount (> 0.1 change)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6s/gj2fjqpx7kd1zydwmjp477dw0000gn/T/ipykernel_65573/3669344195.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  issue_diff['diff_magnitude'] = abs(issue_diff['issue_amount_new'] - issue_diff['issue_amount_old'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RTRS: 2024090506085900\n",
      "  Old issue_amount: 7.94\n",
      "  New issue_amount: 0.00\n",
      "  Difference: -7.94\n",
      "  Percent change: -100.0%\n",
      "\n",
      "RTRS: 2024090506086200\n",
      "  Old issue_amount: 7.94\n",
      "  New issue_amount: 0.00\n",
      "  Difference: -7.94\n",
      "  Percent change: -100.0%\n",
      "\n",
      "RTRS: 2024090900624200\n",
      "  Old issue_amount: 7.94\n",
      "  New issue_amount: 0.00\n",
      "  Difference: -7.94\n",
      "  Percent change: -100.0%\n",
      "\n",
      "RTRS: 2024090911192900\n",
      "  Old issue_amount: 7.94\n",
      "  New issue_amount: 0.00\n",
      "  Difference: -7.94\n",
      "  Percent change: -100.0%\n",
      "\n",
      "RTRS: 2024090911190200\n",
      "  Old issue_amount: 7.94\n",
      "  New issue_amount: 0.00\n",
      "  Difference: -7.94\n",
      "  Percent change: -100.0%\n",
      "\n",
      "RTRS: 2024090506086000\n",
      "  Old issue_amount: 7.94\n",
      "  New issue_amount: 0.00\n",
      "  Difference: -7.94\n",
      "  Percent change: -100.0%\n",
      "\n",
      "RTRS: 2024090506073400\n",
      "  Old issue_amount: 7.94\n",
      "  New issue_amount: 0.00\n",
      "  Difference: -7.94\n",
      "  Percent change: -100.0%\n",
      "\n",
      "RTRS: 2024090511634500\n",
      "  Old issue_amount: 8.86\n",
      "  New issue_amount: 3.70\n",
      "  Difference: -5.16\n",
      "  Percent change: -58.2%\n",
      "\n",
      "RTRS: 2024090511627300\n",
      "  Old issue_amount: 8.86\n",
      "  New issue_amount: 3.70\n",
      "  Difference: -5.16\n",
      "  Percent change: -58.2%\n",
      "\n",
      "RTRS: 2024090307616400\n",
      "  Old issue_amount: 8.86\n",
      "  New issue_amount: 3.70\n",
      "  Difference: -5.16\n",
      "  Percent change: -58.2%\n",
      "\n",
      "\n",
      "=== SIGNIFICANT TRADE_HISTORY DIFFERENCES ===\n",
      "Showing examples of significant trade_history differences:\n",
      "\n",
      "RTRS: 2024091804418900\n",
      "  Old shape: (5, 6)\n",
      "  New shape: (5, 6)\n",
      "  Max difference: 1.00 at position (3, 4)\n",
      "  Old value at max diff: 0.00\n",
      "  New value at max diff: 1.00\n",
      "\n",
      "RTRS: 2024091804572700\n",
      "  Old shape: (5, 6)\n",
      "  New shape: (5, 6)\n",
      "  Max difference: 1.00 at position (3, 4)\n",
      "  Old value at max diff: 0.00\n",
      "  New value at max diff: 1.00\n",
      "\n",
      "RTRS: 2024091804539200\n",
      "  Old shape: (5, 6)\n",
      "  New shape: (5, 6)\n",
      "  Max difference: 1.00 at position (4, 4)\n",
      "  Old value at max diff: 1.00\n",
      "  New value at max diff: 0.00\n",
      "\n",
      "\n",
      "=== SIGNIFICANT SIMILAR_TRADE_HISTORY DIFFERENCES ===\n",
      "Showing examples of significant similar_trade_history differences:\n",
      "\n",
      "RTRS: 2024091804459500\n",
      "  Old shape: (5, 6)\n",
      "  New shape: (5, 6)\n",
      "  Max difference: 0.23 at position (4, 2)\n",
      "\n",
      "RTRS: 2024091804459400\n",
      "  Old shape: (5, 6)\n",
      "  New shape: (5, 6)\n",
      "  Max difference: 0.23 at position (4, 2)\n",
      "\n",
      "RTRS: 2024091804469400\n",
      "  Old shape: (5, 6)\n",
      "  New shape: (5, 6)\n",
      "  Max difference: 0.23 at position (4, 2)\n",
      "\n",
      "\n",
      "=== TEXT/CATEGORICAL FIELD DIFFERENCES ===\n",
      "\n",
      "ISSUE_TEXT: 485218 differences\n",
      "  RTRS: 2024091804520800\n",
      "    Old: 'RESTRUCTURING BDS'\n",
      "    New: 'Restructuring Bonds, Series 2015'\n",
      "  RTRS: 2024091804511700\n",
      "    Old: 'RESTRUCTURING BDS'\n",
      "    New: 'Restructuring Bonds, Series 2015'\n",
      "  RTRS: 2024091804512400\n",
      "    Old: 'RESTRUCTURING BDS'\n",
      "    New: 'Restructuring Bonds, Series 2015'\n",
      "\n",
      "INSTRUMENT_PRIMARY_NAME: 485218 differences\n",
      "  RTRS: 2024091804520800\n",
      "    Old: 'RESTRUCTURING BDS 2015'\n",
      "    New: 'Restructuring Bonds, Series 2015'\n",
      "  RTRS: 2024091804511700\n",
      "    Old: 'RESTRUCTURING BDS 2015'\n",
      "    New: 'Restructuring Bonds, Series 2015'\n",
      "  RTRS: 2024091804512400\n",
      "    Old: 'RESTRUCTURING BDS 2015'\n",
      "    New: 'Restructuring Bonds, Series 2015'\n",
      "\n",
      "SERIES_NAME: 468006 differences\n",
      "  RTRS: 2024091804520800\n",
      "    Old: '2015'\n",
      "    New: 'No series name'\n",
      "  RTRS: 2024091804511700\n",
      "    Old: '2015'\n",
      "    New: 'No series name'\n",
      "  RTRS: 2024091804512400\n",
      "    Old: '2015'\n",
      "    New: 'No series name'\n",
      "\n",
      "\n",
      "=== DATE FIELD DIFFERENCES (>1 day) ===\n",
      "\n",
      "refund_date: 6105 significant differences\n",
      "  RTRS: 2024091804524800\n",
      "    Old: 2025-08-01 00:00:00\n",
      "    New: NaT\n",
      "  RTRS: 2024091804551900\n",
      "    Old: 2025-08-01 00:00:00\n",
      "    New: NaT\n",
      "\n",
      "last_refund_date: 16 significant differences\n",
      "  RTRS: 2024091307620700\n",
      "    Old: NaT\n",
      "    New: 2024-12-04 00:00:00\n",
      "  RTRS: 2024091104780300\n",
      "    Old: NaT\n",
      "    New: 2024-12-04 00:00:00\n",
      "\n",
      "next_sink_date: 2206 significant differences\n",
      "  RTRS: 2024091804594400\n",
      "    Old: 2038-06-01 00:00:00\n",
      "    New: NaT\n",
      "  RTRS: 2024091804626700\n",
      "    Old: 2041-06-01 00:00:00\n",
      "    New: NaT\n",
      "\n",
      "previous_coupon_payment_date: 217648 significant differences\n",
      "  RTRS: 2024091804524800\n",
      "    Old: 2024-08-01 00:00:00\n",
      "    New: 2024-08-03 00:00:00\n",
      "  RTRS: 2024091804492000\n",
      "    Old: 2024-08-15 00:00:00\n",
      "    New: 2024-08-18 00:00:00\n",
      "\n",
      "next_coupon_payment_date: 224036 significant differences\n",
      "  RTRS: 2024091804524800\n",
      "    Old: 2025-02-01 00:00:00\n",
      "    New: 2025-02-03 00:00:00\n",
      "  RTRS: 2024091804492000\n",
      "    Old: 2025-02-15 00:00:00\n",
      "    New: 2025-02-18 00:00:00\n",
      "\n",
      "accrual_date: 1139 significant differences\n",
      "  RTRS: 2024091804352400\n",
      "    Old: 2016-07-27 00:00:00\n",
      "    New: 2016-06-15 00:00:00\n",
      "  RTRS: 2024091804352300\n",
      "    Old: 2016-07-27 00:00:00\n",
      "    New: 2016-06-15 00:00:00\n",
      "\n",
      "\n",
      "=== SUMMARY: FIELDS WITH LARGEST NUMERIC DIFFERENCES ===\n",
      "\n",
      "days_to_par:\n",
      "  Max difference: 4.52\n",
      "  RTRS: 2024082100098100\n",
      "  Old: 0.00\n",
      "  New: 4.52\n",
      "\n",
      "days_to_call:\n",
      "  Max difference: 4.52\n",
      "  RTRS: 2024082100098100\n",
      "  Old: 0.00\n",
      "  New: 4.52\n",
      "\n",
      "issue_amount:\n",
      "  Max difference: 7.94\n",
      "  RTRS: 2024090900624200\n",
      "  Old: 7.94\n",
      "  New: 0.00\n",
      "\n",
      "P_min_ago_ys:\n",
      "  Max difference: 3144.31\n",
      "  RTRS: 2024090901462100\n",
      "  Old: 3339.59\n",
      "  New: 195.28\n",
      "\n",
      "S_min_ago_ys:\n",
      "  Max difference: 6052.66\n",
      "  RTRS: 2024091208081000\n",
      "  Old: 42.01\n",
      "  New: 6094.68\n",
      "\n",
      "D_min_ago_ys:\n",
      "  Max difference: 9562.40\n",
      "  RTRS: 2024091712607600\n",
      "  Old: 9561.66\n",
      "  New: -0.74\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nMerged DataFrame shape: {df_merged.shape}\")\n",
    "print(f\"Number of matching rtrs_control_numbers: {len(df_merged)}\")\n",
    "\n",
    "# Function to check if difference is significant (not just rounding error)\n",
    "def is_significant_difference(old_val, new_val, threshold=0.01):\n",
    "    \"\"\"Check if numeric difference is significant (not just rounding)\"\"\"\n",
    "    if pd.isna(old_val) and pd.isna(new_val):\n",
    "        return False\n",
    "    if pd.isna(old_val) != pd.isna(new_val):\n",
    "        return True\n",
    "    if isinstance(old_val, (int, float)) and isinstance(new_val, (int, float)):\n",
    "        return abs(old_val - new_val) > threshold\n",
    "    return old_val != new_val\n",
    "\n",
    "# Function to compare arrays for significant differences\n",
    "def arrays_significantly_different(arr1, arr2, threshold=0.01):\n",
    "    \"\"\"Check if arrays have significant differences\"\"\"\n",
    "    if not isinstance(arr1, (list, np.ndarray)) or not isinstance(arr2, (list, np.ndarray)):\n",
    "        return True\n",
    "    \n",
    "    arr1 = np.array(arr1)\n",
    "    arr2 = np.array(arr2)\n",
    "    \n",
    "    if arr1.shape != arr2.shape:\n",
    "        return True\n",
    "    \n",
    "    # Check if any element has significant difference\n",
    "    if arr1.size == 0 and arr2.size == 0:\n",
    "        return False\n",
    "    \n",
    "    diff = np.abs(arr1 - arr2)\n",
    "    return np.any(diff > threshold)\n",
    "\n",
    "# Check issue_amount for SIGNIFICANT differences\n",
    "print(\"\\n=== SIGNIFICANT ISSUE_AMOUNT DIFFERENCES ===\")\n",
    "issue_diff_mask = []\n",
    "for idx, row in df_merged.iterrows():\n",
    "    if is_significant_difference(row['issue_amount_old'], row['issue_amount_new'], threshold=0.1):\n",
    "        issue_diff_mask.append(True)\n",
    "    else:\n",
    "        issue_diff_mask.append(False)\n",
    "\n",
    "issue_diff = df_merged[issue_diff_mask]\n",
    "print(f\"Found {len(issue_diff)} SIGNIFICANT differences in issue_amount (> 0.1 change)\")\n",
    "\n",
    "# Show examples sorted by magnitude of difference\n",
    "if len(issue_diff) > 0:\n",
    "    issue_diff['diff_magnitude'] = abs(issue_diff['issue_amount_new'] - issue_diff['issue_amount_old'])\n",
    "    issue_diff_sorted = issue_diff.sort_values('diff_magnitude', ascending=False)\n",
    "    \n",
    "    for i, row in issue_diff_sorted.head(10).iterrows():\n",
    "        print(f\"\\nRTRS: {row['rtrs_control_number']}\")\n",
    "        print(f\"  Old issue_amount: {row['issue_amount_old']:.2f}\")\n",
    "        print(f\"  New issue_amount: {row['issue_amount_new']:.2f}\")\n",
    "        print(f\"  Difference: {row['issue_amount_new'] - row['issue_amount_old']:.2f}\")\n",
    "        print(f\"  Percent change: {((row['issue_amount_new'] - row['issue_amount_old']) / row['issue_amount_old'] * 100):.1f}%\")\n",
    "\n",
    "# Check trade history arrays for SIGNIFICANT differences\n",
    "print(\"\\n\\n=== SIGNIFICANT TRADE_HISTORY DIFFERENCES ===\")\n",
    "trade_diff_examples = []\n",
    "for idx, row in df_merged.iterrows():\n",
    "    old_val = row['trade_history_old']\n",
    "    new_val = row['trade_history_new']\n",
    "    \n",
    "    if arrays_significantly_different(old_val, new_val, threshold=0.1):\n",
    "        trade_diff_examples.append((row['rtrs_control_number'], old_val, new_val))\n",
    "    \n",
    "    if len(trade_diff_examples) >= 5:\n",
    "        break\n",
    "\n",
    "print(f\"Showing examples of significant trade_history differences:\")\n",
    "for rtrs, old_val, new_val in trade_diff_examples[:3]:\n",
    "    print(f\"\\nRTRS: {rtrs}\")\n",
    "    print(f\"  Old shape: {np.array(old_val).shape if isinstance(old_val, (list, np.ndarray)) else 'Not array'}\")\n",
    "    print(f\"  New shape: {np.array(new_val).shape if isinstance(new_val, (list, np.ndarray)) else 'Not array'}\")\n",
    "    if isinstance(old_val, (list, np.ndarray)) and isinstance(new_val, (list, np.ndarray)):\n",
    "        old_arr = np.array(old_val)\n",
    "        new_arr = np.array(new_val)\n",
    "        if old_arr.shape == new_arr.shape:\n",
    "            diff = np.abs(old_arr - new_arr)\n",
    "            max_diff_idx = np.unravel_index(np.argmax(diff), diff.shape)\n",
    "            print(f\"  Max difference: {diff[max_diff_idx]:.2f} at position {max_diff_idx}\")\n",
    "            print(f\"  Old value at max diff: {old_arr[max_diff_idx]:.2f}\")\n",
    "            print(f\"  New value at max diff: {new_arr[max_diff_idx]:.2f}\")\n",
    "\n",
    "# Check similar_trade_history for significant differences\n",
    "print(\"\\n\\n=== SIGNIFICANT SIMILAR_TRADE_HISTORY DIFFERENCES ===\")\n",
    "similar_diff_examples = []\n",
    "for idx, row in df_merged.iterrows():\n",
    "    old_val = row['similar_trade_history_old']\n",
    "    new_val = row['similar_trade_history_new']\n",
    "    \n",
    "    if arrays_significantly_different(old_val, new_val, threshold=0.1):\n",
    "        similar_diff_examples.append((row['rtrs_control_number'], old_val, new_val))\n",
    "    \n",
    "    if len(similar_diff_examples) >= 5:\n",
    "        break\n",
    "\n",
    "print(f\"Showing examples of significant similar_trade_history differences:\")\n",
    "for rtrs, old_val, new_val in similar_diff_examples[:3]:\n",
    "    print(f\"\\nRTRS: {rtrs}\")\n",
    "    if isinstance(old_val, (list, np.ndarray)) and isinstance(new_val, (list, np.ndarray)):\n",
    "        old_arr = np.array(old_val)\n",
    "        new_arr = np.array(new_val)\n",
    "        print(f\"  Old shape: {old_arr.shape}\")\n",
    "        print(f\"  New shape: {new_arr.shape}\")\n",
    "        if old_arr.shape == new_arr.shape:\n",
    "            diff = np.abs(old_arr - new_arr)\n",
    "            max_diff_idx = np.unravel_index(np.argmax(diff), diff.shape)\n",
    "            print(f\"  Max difference: {diff[max_diff_idx]:.2f} at position {max_diff_idx}\")\n",
    "\n",
    "# Look for text/categorical differences\n",
    "print(\"\\n\\n=== TEXT/CATEGORICAL FIELD DIFFERENCES ===\")\n",
    "text_fields = ['issue_text', 'instrument_primary_name', 'series_name', 'issuer_name', 'state']\n",
    "\n",
    "for field in text_fields:\n",
    "    if f'{field}_old' in df_merged.columns and f'{field}_new' in df_merged.columns:\n",
    "        diff_mask = df_merged[f'{field}_old'] != df_merged[f'{field}_new']\n",
    "        # Handle NaN comparisons\n",
    "        diff_mask = diff_mask | (df_merged[f'{field}_old'].isna() != df_merged[f'{field}_new'].isna())\n",
    "        \n",
    "        diff_df = df_merged[diff_mask]\n",
    "        if len(diff_df) > 0:\n",
    "            print(f\"\\n{field.upper()}: {len(diff_df)} differences\")\n",
    "            for i, row in diff_df.head(3).iterrows():\n",
    "                print(f\"  RTRS: {row['rtrs_control_number']}\")\n",
    "                print(f\"    Old: '{row[f'{field}_old']}'\")\n",
    "                print(f\"    New: '{row[f'{field}_new']}'\")\n",
    "\n",
    "# Date field differences\n",
    "print(\"\\n\\n=== DATE FIELD DIFFERENCES (>1 day) ===\")\n",
    "date_fields = ['refund_date', 'last_refund_date', 'next_sink_date', 'previous_coupon_payment_date', \n",
    "               'next_coupon_payment_date', 'dated_date', 'accrual_date']\n",
    "\n",
    "for field in date_fields:\n",
    "    if f'{field}_old' in df_merged.columns and f'{field}_new' in df_merged.columns:\n",
    "        # Convert to datetime if needed\n",
    "        old_dates = pd.to_datetime(df_merged[f'{field}_old'], errors='coerce')\n",
    "        new_dates = pd.to_datetime(df_merged[f'{field}_new'], errors='coerce')\n",
    "        \n",
    "        # Find differences > 1 day\n",
    "        diff_days = abs((new_dates - old_dates).dt.days)\n",
    "        significant_diff = diff_days > 1\n",
    "        \n",
    "        # Also check for NaT mismatches\n",
    "        nat_mismatch = (old_dates.isna() != new_dates.isna())\n",
    "        \n",
    "        diff_mask = significant_diff | nat_mismatch\n",
    "        diff_df = df_merged[diff_mask]\n",
    "        \n",
    "        if len(diff_df) > 0:\n",
    "            print(f\"\\n{field}: {len(diff_df)} significant differences\")\n",
    "            for i, row in diff_df.head(2).iterrows():\n",
    "                print(f\"  RTRS: {row['rtrs_control_number']}\")\n",
    "                print(f\"    Old: {row[f'{field}_old']}\")\n",
    "                print(f\"    New: {row[f'{field}_new']}\")\n",
    "\n",
    "# Summary of biggest numeric differences\n",
    "print(\"\\n\\n=== SUMMARY: FIELDS WITH LARGEST NUMERIC DIFFERENCES ===\")\n",
    "numeric_fields = ['days_to_par', 'days_to_call', 'avg_life', 'duration', 'issue_amount', \n",
    "                  'P_min_ago_ys', 'S_min_ago_ys', 'D_min_ago_ys']\n",
    "\n",
    "for field in numeric_fields:\n",
    "    if f'{field}_old' in df_merged.columns and f'{field}_new' in df_merged.columns:\n",
    "        try:\n",
    "            diff = abs(df_merged[f'{field}_new'] - df_merged[f'{field}_old'])\n",
    "            max_diff = diff.max()\n",
    "            if max_diff > 0.1:  # Only show if max difference > 0.1\n",
    "                max_idx = diff.idxmax()\n",
    "                row = df_merged.loc[max_idx]\n",
    "                print(f\"\\n{field}:\")\n",
    "                print(f\"  Max difference: {max_diff:.2f}\")\n",
    "                print(f\"  RTRS: {row['rtrs_control_number']}\")\n",
    "                print(f\"  Old: {row[f'{field}_old']:.2f}\")\n",
    "                print(f\"  New: {row[f'{field}_new']:.2f}\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE 1: ISSUE AMOUNT DROPPED TO ZERO\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RTRS: 2024090900624200\n",
      "================================================================================\n",
      "\n",
      "issue_amount:\n",
      "  OLD: 7.9377184\n",
      "  NEW: 0.0\n",
      "\n",
      "cusip:\n",
      "  OLD: 34161HAV8\n",
      "  NEW: 34161HAV8\n",
      "\n",
      "instrument_primary_name:\n",
      "  OLD: BDS 2019 A\n",
      "  NEW: AGM Sunshine Skyway Revenue Bonds - Series 2019A\n",
      "\n",
      "issue_text:\n",
      "  OLD: BDS\n",
      "  NEW: AGM Sunshine Skyway Revenue Bonds - Series 2019A\n",
      "\n",
      "series_name:\n",
      "  OLD: 2019 A\n",
      "  NEW: No series name\n",
      "\n",
      "maturity_date:\n",
      "  OLD: 2038-07-01 00:00:00\n",
      "  NEW: 2038-07-01 00:00:00\n",
      "\n",
      "================================================================================\n",
      "RTRS: 2024090911190200\n",
      "================================================================================\n",
      "\n",
      "issue_amount:\n",
      "  OLD: 7.9377184\n",
      "  NEW: 0.0\n",
      "\n",
      "cusip:\n",
      "  OLD: 34161HAV8\n",
      "  NEW: 34161HAV8\n",
      "\n",
      "instrument_primary_name:\n",
      "  OLD: BDS 2019 A\n",
      "  NEW: AGM Sunshine Skyway Revenue Bonds - Series 2019A\n",
      "\n",
      "issue_text:\n",
      "  OLD: BDS\n",
      "  NEW: AGM Sunshine Skyway Revenue Bonds - Series 2019A\n",
      "\n",
      "series_name:\n",
      "  OLD: 2019 A\n",
      "  NEW: No series name\n",
      "\n",
      "maturity_date:\n",
      "  OLD: 2038-07-01 00:00:00\n",
      "  NEW: 2038-07-01 00:00:00\n",
      "\n",
      "================================================================================\n",
      "RTRS: 2024090911192900\n",
      "================================================================================\n",
      "\n",
      "issue_amount:\n",
      "  OLD: 7.9377184\n",
      "  NEW: 0.0\n",
      "\n",
      "cusip:\n",
      "  OLD: 34161HAV8\n",
      "  NEW: 34161HAV8\n",
      "\n",
      "instrument_primary_name:\n",
      "  OLD: BDS 2019 A\n",
      "  NEW: AGM Sunshine Skyway Revenue Bonds - Series 2019A\n",
      "\n",
      "issue_text:\n",
      "  OLD: BDS\n",
      "  NEW: AGM Sunshine Skyway Revenue Bonds - Series 2019A\n",
      "\n",
      "series_name:\n",
      "  OLD: 2019 A\n",
      "  NEW: No series name\n",
      "\n",
      "maturity_date:\n",
      "  OLD: 2038-07-01 00:00:00\n",
      "  NEW: 2038-07-01 00:00:00\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 2: LARGE ISSUE AMOUNT REDUCTION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RTRS: 2024091804520800\n",
      "================================================================================\n",
      "\n",
      "issue_amount:\n",
      "  OLD: 9.000917\n",
      "  NEW: 7.7140365\n",
      "\n",
      "cusip:\n",
      "  OLD: 91802RBS7\n",
      "  NEW: 91802RBS7\n",
      "\n",
      "instrument_primary_name:\n",
      "  OLD: RESTRUCTURING BDS 2015\n",
      "  NEW: Restructuring Bonds, Series 2015\n",
      "\n",
      "issue_text:\n",
      "  OLD: RESTRUCTURING BDS\n",
      "  NEW: Restructuring Bonds, Series 2015\n",
      "\n",
      "maturity_date:\n",
      "  OLD: 2027-06-15 00:00:00\n",
      "  NEW: 2027-06-15 00:00:00\n",
      "\n",
      "state:\n",
      "  OLD: N/A\n",
      "  NEW: N/A\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 3: DRAMATIC TEXT FIELD CHANGES\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RTRS: 2024091804520800\n",
      "================================================================================\n",
      "\n",
      "issue_text:\n",
      "  OLD: RESTRUCTURING BDS\n",
      "  NEW: Restructuring Bonds, Series 2015\n",
      "\n",
      "instrument_primary_name:\n",
      "  OLD: RESTRUCTURING BDS 2015\n",
      "  NEW: Restructuring Bonds, Series 2015\n",
      "\n",
      "series_name:\n",
      "  OLD: 2015\n",
      "  NEW: No series name\n",
      "\n",
      "issuer_name:\n",
      "  OLD: N/A\n",
      "  NEW: N/A\n",
      "\n",
      "================================================================================\n",
      "RTRS: 2024091804511700\n",
      "================================================================================\n",
      "\n",
      "issue_text:\n",
      "  OLD: RESTRUCTURING BDS\n",
      "  NEW: Restructuring Bonds, Series 2015\n",
      "\n",
      "instrument_primary_name:\n",
      "  OLD: RESTRUCTURING BDS 2015\n",
      "  NEW: Restructuring Bonds, Series 2015\n",
      "\n",
      "series_name:\n",
      "  OLD: 2015\n",
      "  NEW: No series name\n",
      "\n",
      "issuer_name:\n",
      "  OLD: N/A\n",
      "  NEW: N/A\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 4: EXTREME YIELD SPREAD METRIC CHANGES\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RTRS: 2024091713803900\n",
      "================================================================================\n",
      "\n",
      "P_min_ago_ys:\n",
      "  OLD: 2349.11\n",
      "  NEW: 2349.11\n",
      "\n",
      "S_min_ago_ys:\n",
      "  OLD: 30.09\n",
      "  NEW: 2349.11\n",
      "  DIFF: 2319.02 (+7706.5%)\n",
      "\n",
      "D_min_ago_ys:\n",
      "  OLD: 2349.11\n",
      "  NEW: 2349.11\n",
      "\n",
      "issue_amount:\n",
      "  OLD: 7.606005\n",
      "  NEW: 7.606005\n",
      "\n",
      "yield:\n",
      "  OLD: 320.50\n",
      "  NEW: 320.50\n",
      "\n",
      "================================================================================\n",
      "RTRS: 2024091709007300\n",
      "================================================================================\n",
      "\n",
      "P_min_ago_ys:\n",
      "  OLD: 1624.49\n",
      "  NEW: 1624.49\n",
      "\n",
      "S_min_ago_ys:\n",
      "  OLD: 193.69\n",
      "  NEW: 1624.49\n",
      "  DIFF: 1430.80 (+738.7%)\n",
      "\n",
      "D_min_ago_ys:\n",
      "  OLD: 4824.25\n",
      "  NEW: 4824.25\n",
      "\n",
      "issue_amount:\n",
      "  OLD: 8.799968\n",
      "  NEW: 8.477122\n",
      "\n",
      "yield:\n",
      "  OLD: 1439.70\n",
      "  NEW: 1439.70\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 5: SIGNIFICANT DATE CHANGES\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RTRS: 2024091804524800\n",
      "================================================================================\n",
      "\n",
      "refund_date:\n",
      "  OLD: 2025-08-01 00:00:00\n",
      "  NEW: NaN\n",
      "\n",
      "last_refund_date:\n",
      "  OLD: 2025-08-01 00:00:00\n",
      "  NEW: 2025-08-01 00:00:00\n",
      "\n",
      "next_coupon_payment_date:\n",
      "  OLD: 2025-02-01 00:00:00\n",
      "  NEW: 2025-02-03 00:00:00\n",
      "\n",
      "previous_coupon_payment_date:\n",
      "  OLD: 2024-08-01 00:00:00\n",
      "  NEW: 2024-08-03 00:00:00\n",
      "\n",
      "maturity_date:\n",
      "  OLD: 2025-08-01 00:00:00\n",
      "  NEW: 2025-08-01 00:00:00\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 6: TRADE HISTORY ARRAY CHANGES\n",
      "================================================================================\n",
      "\n",
      "RTRS: 2024091804418900\n",
      "Trade History Shape: (5, 6)\n",
      "\n",
      "OLD trade_history:\n",
      "[[201.45007719 119.2          5.69896984   0.           0.\n",
      "    2.18469143]\n",
      " [201.45007719 119.2          4.39794016   0.           1.\n",
      "    2.18469143]\n",
      " [157.43210291  84.1          4.39794016   0.           0.\n",
      "    2.18469143]\n",
      " [201.45007719 119.2          6.69896984   0.           0.\n",
      "    2.18469143]\n",
      " [201.45007719 119.2          6.47712135   0.           1.\n",
      "    2.18469143]]\n",
      "\n",
      "NEW trade_history:\n",
      "[[201.45007719 119.2          5.69896984   0.           0.\n",
      "    2.18469143]\n",
      " [201.45007719 119.2          4.39794016   0.           1.\n",
      "    2.18469143]\n",
      " [157.43210291  84.1          4.39794016   0.           0.\n",
      "    2.18469143]\n",
      " [201.45007719 119.2          6.47712135   0.           1.\n",
      "    2.18469143]\n",
      " [201.45007719 119.2          5.69896984   0.           1.\n",
      "    2.18469143]]\n",
      "\n",
      "DIFFERENCE matrix:\n",
      "[[0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.22184849 0.         1.         0.        ]\n",
      " [0.         0.         0.77815151 0.         0.         0.        ]]\n",
      "\n",
      "Max difference: 1.00 at position (3, 4)\n",
      "\n",
      "================================================================================\n",
      "RTRS: 2024091804418900\n",
      "================================================================================\n",
      "\n",
      "issue_amount:\n",
      "  OLD: 8.064589\n",
      "  NEW: 8.0645895\n",
      "\n",
      "trade_count:\n",
      "  OLD: N/A\n",
      "  NEW: N/A\n",
      "\n",
      "yield:\n",
      "  OLD: 490.80\n",
      "  NEW: 490.80\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Issue amounts that went to zero: 7\n",
      "Issue text expanded (short to long): 376,474\n",
      "Series name changed to 'No series name': 491,828\n",
      "Refund dates that were removed (became NaT): 4,393\n"
     ]
    }
   ],
   "source": [
    "# Helper function to display side-by-side comparison\n",
    "def show_side_by_side(rtrs, fields_to_show):\n",
    "    \"\"\"Display old vs new values for specified fields\"\"\"\n",
    "    row = df_merged[df_merged['rtrs_control_number'] == rtrs].iloc[0]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RTRS: {rtrs}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for field in fields_to_show:\n",
    "        old_val = row.get(f'{field}_old', 'N/A')\n",
    "        new_val = row.get(f'{field}_new', 'N/A')\n",
    "        \n",
    "        # Format values for better display\n",
    "        if isinstance(old_val, float) and not pd.isna(old_val):\n",
    "            old_str = f\"{old_val:.2f}\"\n",
    "        elif pd.isna(old_val):\n",
    "            old_str = \"NaN\"\n",
    "        else:\n",
    "            old_str = str(old_val)\n",
    "            \n",
    "        if isinstance(new_val, float) and not pd.isna(new_val):\n",
    "            new_str = f\"{new_val:.2f}\"\n",
    "        elif pd.isna(new_val):\n",
    "            new_str = \"NaN\"\n",
    "        else:\n",
    "            new_str = str(new_val)\n",
    "        \n",
    "        print(f\"\\n{field}:\")\n",
    "        print(f\"  OLD: {old_str}\")\n",
    "        print(f\"  NEW: {new_str}\")\n",
    "        \n",
    "        # Show difference for numeric fields\n",
    "        if isinstance(old_val, (int, float)) and isinstance(new_val, (int, float)) and not pd.isna(old_val) and not pd.isna(new_val):\n",
    "            diff = new_val - old_val\n",
    "            if abs(diff) > 0.01:\n",
    "                pct_change = (diff / old_val * 100) if old_val != 0 else float('inf')\n",
    "                print(f\"  DIFF: {diff:.2f} ({pct_change:+.1f}%)\")\n",
    "\n",
    "# 1. EXTREME ISSUE_AMOUNT CHANGES (100% loss)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE 1: ISSUE AMOUNT DROPPED TO ZERO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find examples where issue_amount went to 0\n",
    "zero_issue_mask = (df_merged['issue_amount_old'] > 0) & (df_merged['issue_amount_new'] == 0)\n",
    "zero_examples = df_merged[zero_issue_mask].head(3)\n",
    "\n",
    "for idx, row in zero_examples.iterrows():\n",
    "    show_side_by_side(\n",
    "        row['rtrs_control_number'],\n",
    "        ['issue_amount', 'cusip', 'instrument_primary_name', 'issue_text', 'series_name', 'maturity_date']\n",
    "    )\n",
    "\n",
    "# 2. LARGE ISSUE_AMOUNT REDUCTION (but not to zero)\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE 2: LARGE ISSUE AMOUNT REDUCTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find large reductions that aren't to zero\n",
    "large_reduction_mask = (\n",
    "    (df_merged['issue_amount_old'] > 0) & \n",
    "    (df_merged['issue_amount_new'] > 0) & \n",
    "    (abs(df_merged['issue_amount_old'] - df_merged['issue_amount_new']) > 1)\n",
    ")\n",
    "large_reduction = df_merged[large_reduction_mask].head(1)\n",
    "\n",
    "for idx, row in large_reduction.iterrows():\n",
    "    show_side_by_side(\n",
    "        row['rtrs_control_number'],\n",
    "        ['issue_amount', 'cusip', 'instrument_primary_name', 'issue_text', 'maturity_date', 'state']\n",
    "    )\n",
    "\n",
    "# 3. TEXT FIELD CHANGES\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE 3: DRAMATIC TEXT FIELD CHANGES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find cases with significant text changes\n",
    "text_change_mask = (\n",
    "    (df_merged['issue_text_old'].str.len() < 20) & \n",
    "    (df_merged['issue_text_new'].str.len() > 30)\n",
    ")\n",
    "text_examples = df_merged[text_change_mask].head(2)\n",
    "\n",
    "for idx, row in text_examples.iterrows():\n",
    "    show_side_by_side(\n",
    "        row['rtrs_control_number'],\n",
    "        ['issue_text', 'instrument_primary_name', 'series_name', 'issuer_name']\n",
    "    )\n",
    "\n",
    "# 4. EXTREME YIELD SPREAD CHANGES\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE 4: EXTREME YIELD SPREAD METRIC CHANGES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find extreme changes in yield spread metrics\n",
    "extreme_ys_mask = (\n",
    "    (abs(df_merged['P_min_ago_ys_new'] - df_merged['P_min_ago_ys_old']) > 1000) |\n",
    "    (abs(df_merged['S_min_ago_ys_new'] - df_merged['S_min_ago_ys_old']) > 1000)\n",
    ")\n",
    "extreme_ys = df_merged[extreme_ys_mask].head(2)\n",
    "\n",
    "for idx, row in extreme_ys.iterrows():\n",
    "    show_side_by_side(\n",
    "        row['rtrs_control_number'],\n",
    "        ['P_min_ago_ys', 'S_min_ago_ys', 'D_min_ago_ys', 'issue_amount', 'yield']\n",
    "    )\n",
    "\n",
    "# 5. DATE FIELD CHANGES\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE 5: SIGNIFICANT DATE CHANGES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find date field changes\n",
    "date_cols = ['refund_date', 'next_coupon_payment_date', 'previous_coupon_payment_date']\n",
    "for date_col in date_cols:\n",
    "    # Find cases where dates differ significantly or NaT mismatch\n",
    "    old_dates = pd.to_datetime(df_merged[f'{date_col}_old'], errors='coerce')\n",
    "    new_dates = pd.to_datetime(df_merged[f'{date_col}_new'], errors='coerce')\n",
    "    \n",
    "    nat_mismatch = (old_dates.isna() != new_dates.isna())\n",
    "    if nat_mismatch.any():\n",
    "        example = df_merged[nat_mismatch].iloc[0]\n",
    "        show_side_by_side(\n",
    "            example['rtrs_control_number'],\n",
    "            ['refund_date', 'last_refund_date', 'next_coupon_payment_date', 'previous_coupon_payment_date', 'maturity_date']\n",
    "        )\n",
    "        break\n",
    "\n",
    "# 6. TRADE HISTORY ARRAY DIFFERENCES\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE 6: TRADE HISTORY ARRAY CHANGES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find trade history differences\n",
    "for idx, row in df_merged.head(1000).iterrows():\n",
    "    old_th = row['trade_history_old']\n",
    "    new_th = row['trade_history_new']\n",
    "    \n",
    "    if isinstance(old_th, np.ndarray) and isinstance(new_th, np.ndarray):\n",
    "        if old_th.shape == new_th.shape and old_th.size > 0:\n",
    "            diff = np.abs(old_th - new_th)\n",
    "            if np.any(diff > 0.5):  # Find significant differences\n",
    "                print(f\"\\nRTRS: {row['rtrs_control_number']}\")\n",
    "                print(f\"Trade History Shape: {old_th.shape}\")\n",
    "                print(\"\\nOLD trade_history:\")\n",
    "                print(old_th)\n",
    "                print(\"\\nNEW trade_history:\")\n",
    "                print(new_th)\n",
    "                print(\"\\nDIFFERENCE matrix:\")\n",
    "                print(diff)\n",
    "                print(f\"\\nMax difference: {np.max(diff):.2f} at position {np.unravel_index(np.argmax(diff), diff.shape)}\")\n",
    "                \n",
    "                # Also show related fields\n",
    "                show_side_by_side(\n",
    "                    row['rtrs_control_number'],\n",
    "                    ['issue_amount', 'trade_count', 'yield']\n",
    "                )\n",
    "                break\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count major difference categories\n",
    "zero_issue_count = ((df_merged['issue_amount_old'] > 0) & (df_merged['issue_amount_new'] == 0)).sum()\n",
    "text_expanded = ((df_merged['issue_text_old'].str.len() < 20) & (df_merged['issue_text_new'].str.len() > 30)).sum()\n",
    "series_to_none = (df_merged['series_name_new'] == 'No series name').sum()\n",
    "refund_date_removed = (~df_merged['refund_date_old'].isna() & df_merged['refund_date_new'].isna()).sum()\n",
    "\n",
    "print(f\"\\nIssue amounts that went to zero: {zero_issue_count:,}\")\n",
    "print(f\"Issue text expanded (short to long): {text_expanded:,}\")\n",
    "print(f\"Series name changed to 'No series name': {series_to_none:,}\")\n",
    "print(f\"Refund dates that were removed (became NaT): {refund_date_removed:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rtrs_control_number</th>\n",
       "      <th>cusip</th>\n",
       "      <th>yield</th>\n",
       "      <th>is_callable</th>\n",
       "      <th>refund_date</th>\n",
       "      <th>accrual_date</th>\n",
       "      <th>dated_date</th>\n",
       "      <th>next_sink_date</th>\n",
       "      <th>coupon</th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>...</th>\n",
       "      <th>D_min_ago_ago</th>\n",
       "      <th>D_min_ago_qdiff</th>\n",
       "      <th>P_min_ago_ys</th>\n",
       "      <th>P_min_ago_ttypes</th>\n",
       "      <th>P_min_ago_ago</th>\n",
       "      <th>P_min_ago_qdiff</th>\n",
       "      <th>S_min_ago_ys</th>\n",
       "      <th>S_min_ago_ttypes</th>\n",
       "      <th>S_min_ago_ago</th>\n",
       "      <th>S_min_ago_qdiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025061720786800</td>\n",
       "      <td>112709ZM5</td>\n",
       "      <td>479.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>...</td>\n",
       "      <td>4.282690</td>\n",
       "      <td>5.176094</td>\n",
       "      <td>64.320795</td>\n",
       "      <td>PP</td>\n",
       "      <td>1.531479</td>\n",
       "      <td>0.066212</td>\n",
       "      <td>42.620795</td>\n",
       "      <td>SP</td>\n",
       "      <td>4.282690</td>\n",
       "      <td>5.176094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025061720786600</td>\n",
       "      <td>112709ZM5</td>\n",
       "      <td>479.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>...</td>\n",
       "      <td>4.281942</td>\n",
       "      <td>5.176094</td>\n",
       "      <td>65.609381</td>\n",
       "      <td>PP</td>\n",
       "      <td>5.636037</td>\n",
       "      <td>4.698980</td>\n",
       "      <td>42.620795</td>\n",
       "      <td>SP</td>\n",
       "      <td>4.281942</td>\n",
       "      <td>5.176094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025061720771000</td>\n",
       "      <td>9384292L0</td>\n",
       "      <td>457.7</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>...</td>\n",
       "      <td>4.318919</td>\n",
       "      <td>0.045243</td>\n",
       "      <td>88.795466</td>\n",
       "      <td>PP</td>\n",
       "      <td>6.017536</td>\n",
       "      <td>4.903096</td>\n",
       "      <td>73.799180</td>\n",
       "      <td>SP</td>\n",
       "      <td>4.318919</td>\n",
       "      <td>0.045243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025061720734200</td>\n",
       "      <td>846378EF0</td>\n",
       "      <td>492.3</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>2051-06-01</td>\n",
       "      <td>4.850</td>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.012542</td>\n",
       "      <td>4.397960</td>\n",
       "      <td>-16.697114</td>\n",
       "      <td>PP</td>\n",
       "      <td>4.103359</td>\n",
       "      <td>4.698979</td>\n",
       "      <td>-17.197114</td>\n",
       "      <td>SP</td>\n",
       "      <td>4.115211</td>\n",
       "      <td>5.352185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025061720633100</td>\n",
       "      <td>15114CDB7</td>\n",
       "      <td>555.1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>4.125</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>...</td>\n",
       "      <td>5.574770</td>\n",
       "      <td>4.000046</td>\n",
       "      <td>93.232996</td>\n",
       "      <td>PS</td>\n",
       "      <td>5.574770</td>\n",
       "      <td>4.000046</td>\n",
       "      <td>71.465098</td>\n",
       "      <td>SS</td>\n",
       "      <td>5.853419</td>\n",
       "      <td>4.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rtrs_control_number      cusip  yield  is_callable refund_date  \\\n",
       "0     2025061720786800  112709ZM5  479.0         True         NaT   \n",
       "1     2025061720786600  112709ZM5  479.0         True         NaT   \n",
       "2     2025061720771000  9384292L0  457.7         True         NaT   \n",
       "3     2025061720734200  846378EF0  492.3         True         NaT   \n",
       "4     2025061720633100  15114CDB7  555.1         True         NaT   \n",
       "\n",
       "  accrual_date dated_date next_sink_date  coupon delivery_date  ...  \\\n",
       "0   2021-10-28 2021-10-28            NaT   2.000    2021-10-28  ...   \n",
       "1   2021-10-28 2021-10-28            NaT   2.000    2021-10-28  ...   \n",
       "2   2025-05-28 2025-05-28            NaT   0.000    2025-05-28  ...   \n",
       "3   2025-06-18 2025-06-18     2051-06-01   4.850    2025-06-18  ...   \n",
       "4   2020-09-29 2020-09-01     2025-09-01   4.125    2020-09-29  ...   \n",
       "\n",
       "  D_min_ago_ago D_min_ago_qdiff P_min_ago_ys P_min_ago_ttypes  P_min_ago_ago  \\\n",
       "0      4.282690        5.176094    64.320795               PP       1.531479   \n",
       "1      4.281942        5.176094    65.609381               PP       5.636037   \n",
       "2      4.318919        0.045243    88.795466               PP       6.017536   \n",
       "3      4.012542        4.397960   -16.697114               PP       4.103359   \n",
       "4      5.574770        4.000046    93.232996               PS       5.574770   \n",
       "\n",
       "   P_min_ago_qdiff  S_min_ago_ys  S_min_ago_ttypes  S_min_ago_ago  \\\n",
       "0         0.066212     42.620795                SP       4.282690   \n",
       "1         4.698980     42.620795                SP       4.281942   \n",
       "2         4.903096     73.799180                SP       4.318919   \n",
       "3         4.698979    -17.197114                SP       4.115211   \n",
       "4         4.000046     71.465098                SS       5.853419   \n",
       "\n",
       "   S_min_ago_qdiff  \n",
       "0         5.176094  \n",
       "1         5.176094  \n",
       "2         0.045243  \n",
       "3         5.352185  \n",
       "4         4.000041  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('/Users/gil/git/ficc_python/notebooks/train_model/2025-06-17_2025-05-17_trades_for_all_dates_from_get_processed_data.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.trade_date == '2025-06-04'][:100].to_csv('/Users/gil/Downloads/2025-06-04_100_trades.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
