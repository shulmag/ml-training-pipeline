{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# orig = pd.read_pickle(\"/Users/gil/Downloads/processed_data_yield_spread_with_similar_trades_v2_original.pkl\")\n",
    "# new = pd.read_pickle(\"/Users/gil/Downloads/2025-06-18_2025-01-01_trades_for_all_dates_from_get_processed_data.pkl\")\n",
    "\n",
    "# orig.head()\n",
    "\n",
    "# new.head()\n",
    "\n",
    "# orig.columns\n",
    "\n",
    "# new.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rtrs_control_number</th>\n",
       "      <th>cusip</th>\n",
       "      <th>yield</th>\n",
       "      <th>is_callable</th>\n",
       "      <th>refund_date</th>\n",
       "      <th>accrual_date</th>\n",
       "      <th>dated_date</th>\n",
       "      <th>next_sink_date</th>\n",
       "      <th>coupon</th>\n",
       "      <th>...</th>\n",
       "      <th>D_min_ago_ago</th>\n",
       "      <th>D_min_ago_qdiff</th>\n",
       "      <th>P_min_ago_ys</th>\n",
       "      <th>P_min_ago_ttypes</th>\n",
       "      <th>P_min_ago_ago</th>\n",
       "      <th>P_min_ago_qdiff</th>\n",
       "      <th>S_min_ago_ys</th>\n",
       "      <th>S_min_ago_ttypes</th>\n",
       "      <th>S_min_ago_ago</th>\n",
       "      <th>S_min_ago_qdiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2063959</td>\n",
       "      <td>2025050123093100</td>\n",
       "      <td>544532JX3</td>\n",
       "      <td>370.4</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-02</td>\n",
       "      <td>2024-04-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.248660</td>\n",
       "      <td>3.699057</td>\n",
       "      <td>80.052697</td>\n",
       "      <td>PS</td>\n",
       "      <td>4.063559</td>\n",
       "      <td>4.954247</td>\n",
       "      <td>63.252697</td>\n",
       "      <td>SS</td>\n",
       "      <td>4.248660</td>\n",
       "      <td>3.699057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2063960</td>\n",
       "      <td>2025050123093200</td>\n",
       "      <td>544532JX3</td>\n",
       "      <td>382.3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-02</td>\n",
       "      <td>2024-04-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.248660</td>\n",
       "      <td>3.699057</td>\n",
       "      <td>80.052697</td>\n",
       "      <td>PD</td>\n",
       "      <td>4.063559</td>\n",
       "      <td>4.954247</td>\n",
       "      <td>63.252697</td>\n",
       "      <td>SD</td>\n",
       "      <td>4.248660</td>\n",
       "      <td>3.699057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2063961</td>\n",
       "      <td>2025050123092600</td>\n",
       "      <td>7087966Z5</td>\n",
       "      <td>375.9</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.55</td>\n",
       "      <td>...</td>\n",
       "      <td>5.732462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.344097</td>\n",
       "      <td>PS</td>\n",
       "      <td>5.732462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.306449</td>\n",
       "      <td>SS</td>\n",
       "      <td>6.645146</td>\n",
       "      <td>4.176120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2063962</td>\n",
       "      <td>2025050123092700</td>\n",
       "      <td>7087966Z5</td>\n",
       "      <td>387.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.55</td>\n",
       "      <td>...</td>\n",
       "      <td>5.732462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.344097</td>\n",
       "      <td>PD</td>\n",
       "      <td>5.732462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.306449</td>\n",
       "      <td>SD</td>\n",
       "      <td>6.645146</td>\n",
       "      <td>4.176120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2063963</td>\n",
       "      <td>2025050123077000</td>\n",
       "      <td>576002BK4</td>\n",
       "      <td>358.2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-07-27</td>\n",
       "      <td>2005-07-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.50</td>\n",
       "      <td>...</td>\n",
       "      <td>5.052559</td>\n",
       "      <td>3.699057</td>\n",
       "      <td>59.724004</td>\n",
       "      <td>PD</td>\n",
       "      <td>5.052559</td>\n",
       "      <td>3.699057</td>\n",
       "      <td>-36.121328</td>\n",
       "      <td>SD</td>\n",
       "      <td>6.091165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rtrs_control_number      cusip  yield  is_callable refund_date  \\\n",
       "0     2063959     2025050123093100  544532JX3  370.4        False         NaN   \n",
       "1     2063960     2025050123093200  544532JX3  382.3        False         NaN   \n",
       "2     2063961     2025050123092600  7087966Z5  375.9         True         NaN   \n",
       "3     2063962     2025050123092700  7087966Z5  387.0         True         NaN   \n",
       "4     2063963     2025050123077000  576002BK4  358.2        False         NaN   \n",
       "\n",
       "  accrual_date  dated_date next_sink_date  coupon  ... D_min_ago_ago  \\\n",
       "0   2024-04-02  2024-04-02            NaN    5.00  ...      4.248660   \n",
       "1   2024-04-02  2024-04-02            NaN    5.00  ...      4.248660   \n",
       "2   2017-09-28  2017-09-28            NaN    2.55  ...      5.732462   \n",
       "3   2017-09-28  2017-09-28            NaN    2.55  ...      5.732462   \n",
       "4   2005-07-27  2005-07-27            NaN    5.50  ...      5.052559   \n",
       "\n",
       "  D_min_ago_qdiff P_min_ago_ys P_min_ago_ttypes P_min_ago_ago  \\\n",
       "0        3.699057    80.052697               PS      4.063559   \n",
       "1        3.699057    80.052697               PD      4.063559   \n",
       "2        0.000000   136.344097               PS      5.732462   \n",
       "3        0.000000   136.344097               PD      5.732462   \n",
       "4        3.699057    59.724004               PD      5.052559   \n",
       "\n",
       "   P_min_ago_qdiff  S_min_ago_ys  S_min_ago_ttypes  S_min_ago_ago  \\\n",
       "0         4.954247     63.252697                SS       4.248660   \n",
       "1         4.954247     63.252697                SD       4.248660   \n",
       "2         0.000000     61.306449                SS       6.645146   \n",
       "3         0.000000     61.306449                SD       6.645146   \n",
       "4         3.699057    -36.121328                SD       6.091165   \n",
       "\n",
       "   S_min_ago_qdiff  \n",
       "0         3.699057  \n",
       "1         3.699057  \n",
       "2         4.176120  \n",
       "3         4.176120  \n",
       "4         0.000000  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_orig = orig[orig.trade_date == \"2025-05-01\"]\n",
    "# df_new = new[new.trade_date == \"2025-05-01\"]\n",
    "\n",
    "# df_orig.head()\n",
    "\n",
    "df_new = pd.read_csv(\"2025-05-01_new.csv\")\n",
    "df_orig = pd.read_csv(\"2025-05-01_orig.csv\")\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6s/gj2fjqpx7kd1zydwmjp477dw0000gn/T/ipykernel_49140/458713983.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged = pd.merge(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge results:\n",
      "both          71458\n",
      "right_only     2818\n",
      "left_only       677\n",
      "Name: _merge, dtype: int64\n",
      "\n",
      "\n",
      "Number of matching rtrs_control_numbers: 71458\n",
      "Analyzing differences (this may take a moment)...\n",
      "\n",
      "Columns with differences (sorted by count):\n",
      "------------------------------------------------------------\n",
      "Unnamed: 0                      71458 differences (100.0%)\n",
      "similar_trade_history           51213 differences ( 71.7%)\n",
      "issue_amount                    39086 differences ( 54.7%)\n",
      "P_min_ago_qdiff                 33722 differences ( 47.2%)\n",
      "S_min_ago_qdiff                 32699 differences ( 45.8%)\n",
      "D_min_ago_qdiff                 32551 differences ( 45.6%)\n",
      "min_ys_qdiff                    31477 differences ( 44.0%)\n",
      "max_ys_qdiff                    31407 differences ( 44.0%)\n",
      "max_qty_qdiff                   31275 differences ( 43.8%)\n",
      "min_ago_qdiff                   31200 differences ( 43.7%)\n",
      "quantity                        28332 differences ( 39.6%)\n",
      "target_attention_features       28332 differences ( 39.6%)\n",
      "P_min_ago_ys                    12973 differences ( 18.2%)\n",
      "S_min_ago_ys                    11196 differences ( 15.7%)\n",
      "D_min_ago_ys                    11107 differences ( 15.5%)\n",
      "max_ys_ys                        9226 differences ( 12.9%)\n",
      "last_yield_spread                9146 differences ( 12.8%)\n",
      "min_ago_ys                       9146 differences ( 12.8%)\n",
      "ficc_ycl                         8999 differences ( 12.6%)\n",
      "ficc_treasury_spread             8999 differences ( 12.6%)\n",
      "\n",
      "\n",
      "Anecdotal examples of differences:\n",
      "================================================================================\n",
      "\n",
      "LAST_YIELD_SPREAD differences:\n",
      "----------------------------------------\n",
      "RTRS: 2025050123093100, CUSIP: 544532JX3\n",
      "  Original: 68.05269712032111\n",
      "  New:      68.05269712032128\n",
      "\n",
      "RTRS: 2025050123093200, CUSIP: 544532JX3\n",
      "  Original: 68.05269712032111\n",
      "  New:      68.05269712032128\n",
      "\n",
      "RTRS: 2025050122274400, CUSIP: 915183V53\n",
      "  Original: 25.85574143173642\n",
      "  New:      25.8557414317354\n",
      "\n",
      "RTRS: 2025050122271100, CUSIP: 915183V53\n",
      "  Original: 25.85574143173642\n",
      "  New:      25.8557414317354\n",
      "\n",
      "RTRS: 2025050122044700, CUSIP: 986523TF5\n",
      "  Original: 2.6504627573867765\n",
      "  New:      2.650462757387004\n",
      "\n",
      "\n",
      "LAST_SECONDS_AGO differences:\n",
      "----------------------------------------\n",
      "RTRS: 2025050120748100, CUSIP: 73358WN83\n",
      "  Original: 20592.0\n",
      "  New:      180.0\n",
      "\n",
      "RTRS: 2025050120401500, CUSIP: 73358WWY6\n",
      "  Original: 113.0\n",
      "  New:      509.0\n",
      "\n",
      "RTRS: 2025050119311500, CUSIP: 941468YL8\n",
      "  Original: 2341006.0\n",
      "  New:      28.0\n",
      "\n",
      "RTRS: 2025050119162000, CUSIP: 25477GUW3\n",
      "  Original: 14849.0\n",
      "  New:      60.0\n",
      "\n",
      "RTRS: 2025050119161700, CUSIP: 25477GUW3\n",
      "  Original: 14849.0\n",
      "  New:      60.0\n",
      "\n",
      "\n",
      "TRADE_HISTORY differences:\n",
      "----------------------------------------\n",
      "RTRS: 2025050121161800, CUSIP: 921626PU5\n",
      "  Original: [[51.33167746 25.          6.55569887  0.          1.          4.47064566]\n",
      " [52.43167746 26.1         6.55569887  0.          0.          4.47107157]\n",
      " [52.43167746 26.1         6.55569887  1.          0.          4.47107157]\n",
      " [51.33167746 25.          6.69896984  0.          1.          4.49590494]\n",
      " [46.23780303 33.          4.69896984  0.          0.          5.00089373]]\n",
      "  New:      [[51.33167746 25.          6.55569887  0.          1.          4.47064566]\n",
      " [52.43167746 26.1         6.55569887  0.          0.          4.47107157]\n",
      " [52.43167746 26.1         6.55569887  1.          0.          4.47107157]\n",
      " [51.33167746 25.          7.01724195  0.          1.          4.49590494]\n",
      " [46.23780303 33.          4.69896984  0.          0.          5.00089373]]\n",
      "\n",
      "RTRS: 2025050121161700, CUSIP: 921626PU5\n",
      "  Original: [[51.33167746 25.          6.55569887  0.          1.          4.47064566]\n",
      " [52.43167746 26.1         6.55569887  0.          0.          4.47107157]\n",
      " [52.43167746 26.1         6.55569887  1.          0.          4.47107157]\n",
      " [51.33167746 25.          6.69896984  0.          1.          4.49590494]\n",
      " [46.23780303 33.          4.69896984  0.          0.          5.00089373]]\n",
      "  New:      [[51.33167746 25.          6.55569887  0.          1.          4.47064566]\n",
      " [52.43167746 26.1         6.55569887  0.          0.          4.47107157]\n",
      " [52.43167746 26.1         6.55569887  1.          0.          4.47107157]\n",
      " [51.33167746 25.          7.01724195  0.          1.          4.49590494]\n",
      " [46.23780303 33.          4.69896984  0.          0.          5.00089373]]\n",
      "\n",
      "RTRS: 2025050121161600, CUSIP: 921626PU5\n",
      "  Original: [[51.33167746 25.          6.55569887  0.          1.          4.47063096]\n",
      " [52.43167746 26.1         6.55569887  0.          0.          4.47105689]\n",
      " [52.43167746 26.1         6.55569887  1.          0.          4.47105689]\n",
      " [51.33167746 25.          6.69896984  0.          1.          4.49589108]\n",
      " [46.23780303 33.          4.69896984  0.          0.          5.00088939]]\n",
      "  New:      [[51.33167746 25.          6.55569887  0.          1.          4.47063096]\n",
      " [52.43167746 26.1         6.55569887  0.          0.          4.47105689]\n",
      " [52.43167746 26.1         6.55569887  1.          0.          4.47105689]\n",
      " [51.33167746 25.          7.01724195  0.          1.          4.49589108]\n",
      " [46.23780303 33.          4.69896984  0.          0.          5.00088939]]\n",
      "\n",
      "RTRS: 2025050121164200, CUSIP: 64972JJU3\n",
      "  Original: [[  5.54268036 -49.           5.75204849   0.           1.\n",
      "    3.78518742]\n",
      " [ 11.04268036 -43.5          5.33243847   1.           0.\n",
      "    3.993965  ]\n",
      " [ 15.84268036 -38.7          4.17609119   0.           0.\n",
      "    4.01118969]\n",
      " [  7.6728803  -34.1          5.86628723   1.           0.\n",
      "    5.04833691]\n",
      " [  1.7728803  -40.           6.69896984   0.           1.\n",
      "    5.06178411]]\n",
      "  New:      [[  5.54268036 -49.           5.75204849   0.           1.\n",
      "    3.78518742]\n",
      " [ 11.04268036 -43.5          5.33243847   1.           0.\n",
      "    3.993965  ]\n",
      " [ 15.84268036 -38.7          4.17609119   0.           0.\n",
      "    4.01118969]\n",
      " [  7.6728803  -34.1          5.86628723   1.           0.\n",
      "    5.04833691]\n",
      " [  1.7728803  -40.           7.00860023   0.           1.\n",
      "    5.06178411]]\n",
      "\n",
      "RTRS: 2025050121163400, CUSIP: 64972JJU3\n",
      "  Original: [[  5.54268036 -49.           5.75204849   0.           1.\n",
      "    3.78518742]\n",
      " [ 11.04268036 -43.5          5.33243847   1.           0.\n",
      "    3.993965  ]\n",
      " [ 15.84268036 -38.7          4.17609119   0.           0.\n",
      "    4.01118969]\n",
      " [  7.6728803  -34.1          5.86628723   1.           0.\n",
      "    5.04833691]\n",
      " [  1.7728803  -40.           6.69896984   0.           1.\n",
      "    5.06178411]]\n",
      "  New:      [[  5.54268036 -49.           5.75204849   0.           1.\n",
      "    3.78518742]\n",
      " [ 11.04268036 -43.5          5.33243847   1.           0.\n",
      "    3.993965  ]\n",
      " [ 15.84268036 -38.7          4.17609119   0.           0.\n",
      "    4.01118969]\n",
      " [  7.6728803  -34.1          5.86628723   1.           0.\n",
      "    5.04833691]\n",
      " [  1.7728803  -40.           7.00860023   0.           1.\n",
      "    5.06178411]]\n",
      "\n",
      "\n",
      "LAST_TRADE_TYPE differences:\n",
      "----------------------------------------\n",
      "RTRS: 2025050119311500, CUSIP: 941468YL8\n",
      "  Original: P\n",
      "  New:      D\n",
      "\n",
      "RTRS: 2025050118686800, CUSIP: 13063DXC7\n",
      "  Original: S\n",
      "  New:      D\n",
      "\n",
      "RTRS: 2025050118629800, CUSIP: 13063DXC7\n",
      "  Original: S\n",
      "  New:      D\n",
      "\n",
      "RTRS: 2025050118360400, CUSIP: 64990FQ23\n",
      "  Original: D\n",
      "  New:      S\n",
      "\n",
      "RTRS: 2025050118366500, CUSIP: 64990FQ23\n",
      "  Original: D\n",
      "  New:      S\n",
      "\n",
      "\n",
      "LAST_SIZE differences:\n",
      "----------------------------------------\n",
      "RTRS: 2025050120702600, CUSIP: 46247SFR0\n",
      "  Original: 5000000.0\n",
      "  New:      8700000.0\n",
      "\n",
      "RTRS: 2025050120401500, CUSIP: 73358WWY6\n",
      "  Original: 20000.0\n",
      "  New:      250000.0\n",
      "\n",
      "RTRS: 2025050120203100, CUSIP: 546417LH7\n",
      "  Original: 5000000.0\n",
      "  New:      7500000.0\n",
      "\n",
      "RTRS: 2025050120203900, CUSIP: 546417LH7\n",
      "  Original: 5000000.0\n",
      "  New:      7500000.0\n",
      "\n",
      "RTRS: 2025050120021600, CUSIP: 70914P4E9\n",
      "  Original: 5000000.0\n",
      "  New:      6260000.0\n",
      "\n",
      "\n",
      "\n",
      "Analyzing differences per row...\n",
      "\n",
      "Completely identical rows: 0 out of 71458 (0.0%)\n",
      "Rows with at least one difference: 71458\n",
      "\n",
      "\n",
      "Distribution of differences per row:\n",
      "1     1849\n",
      "2     7428\n",
      "3     7675\n",
      "4     3790\n",
      "5     4078\n",
      "6     4252\n",
      "7     2908\n",
      "8     2066\n",
      "9     1700\n",
      "10    2811\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Merge the dataframes on rtrs_control_number\n",
    "merged = pd.merge(\n",
    "    df_orig, \n",
    "    df_new, \n",
    "    on='rtrs_control_number', \n",
    "    suffixes=('_orig', '_new'),\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Check merge results\n",
    "print(\"Merge results:\")\n",
    "print(merged['_merge'].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Find rows that exist in both\n",
    "both = merged[merged['_merge'] == 'both'].copy()\n",
    "print(f\"Number of matching rtrs_control_numbers: {len(both)}\")\n",
    "\n",
    "# Helper function to safely compare values\n",
    "def safe_compare(val1, val2):\n",
    "    \"\"\"Compare two values, handling arrays, NaN, etc.\"\"\"\n",
    "    # Both are NaN/None\n",
    "    if pd.isna(val1) and pd.isna(val2):\n",
    "        return True\n",
    "    # One is NaN, other isn't\n",
    "    if pd.isna(val1) or pd.isna(val2):\n",
    "        return False\n",
    "    # Handle arrays/lists\n",
    "    if isinstance(val1, (list, np.ndarray)) or isinstance(val2, (list, np.ndarray)):\n",
    "        try:\n",
    "            return np.array_equal(val1, val2)\n",
    "        except:\n",
    "            return str(val1) == str(val2)\n",
    "    # Regular comparison\n",
    "    try:\n",
    "        return val1 == val2\n",
    "    except:\n",
    "        return str(val1) == str(val2)\n",
    "\n",
    "# Function to compare columns\n",
    "def compare_columns(df, orig_suffix='_orig', new_suffix='_new'):\n",
    "    # Get base column names (without suffixes)\n",
    "    base_cols = [col.replace(orig_suffix, '').replace(new_suffix, '') \n",
    "                 for col in df.columns \n",
    "                 if col.endswith(orig_suffix)]\n",
    "    \n",
    "    differences = {}\n",
    "    \n",
    "    for col in base_cols:\n",
    "        orig_col = f\"{col}{orig_suffix}\"\n",
    "        new_col = f\"{col}{new_suffix}\"\n",
    "        \n",
    "        if orig_col in df.columns and new_col in df.columns:\n",
    "            # Count differences row by row\n",
    "            diff_count = 0\n",
    "            for idx, row in df.iterrows():\n",
    "                if not safe_compare(row[orig_col], row[new_col]):\n",
    "                    diff_count += 1\n",
    "            \n",
    "            if diff_count > 0:\n",
    "                differences[col] = {\n",
    "                    'count': diff_count,\n",
    "                    'percentage': (diff_count / len(df)) * 100\n",
    "                }\n",
    "    \n",
    "    return differences\n",
    "\n",
    "# Get differences\n",
    "print(\"Analyzing differences (this may take a moment)...\")\n",
    "diffs = compare_columns(both)\n",
    "\n",
    "# Sort by number of differences\n",
    "sorted_diffs = sorted(diffs.items(), key=lambda x: x[1]['count'], reverse=True)\n",
    "\n",
    "print(\"\\nColumns with differences (sorted by count):\")\n",
    "print(\"-\" * 60)\n",
    "for col, info in sorted_diffs[:20]:  # Show top 20\n",
    "    print(f\"{col:<30} {info['count']:>6} differences ({info['percentage']:>5.1f}%)\")\n",
    "\n",
    "# Show some anecdotal examples\n",
    "print(\"\\n\\nAnecdotal examples of differences:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Pick a few interesting columns to show examples\n",
    "example_cols = ['yield', 'dollar_price', 'last_yield_spread', 'last_seconds_ago', \n",
    "                'trade_history', 'last_trade_type', 'last_size']\n",
    "\n",
    "for col in example_cols:\n",
    "    if col in [c for c, _ in sorted_diffs]:\n",
    "        print(f\"\\n{col.upper()} differences:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        orig_col = f\"{col}_orig\"\n",
    "        new_col = f\"{col}_new\"\n",
    "        \n",
    "        # Find rows with differences\n",
    "        diff_indices = []\n",
    "        for idx, row in both.iterrows():\n",
    "            if not safe_compare(row[orig_col], row[new_col]):\n",
    "                diff_indices.append(idx)\n",
    "                if len(diff_indices) >= 5:  # Only show 5 examples\n",
    "                    break\n",
    "        \n",
    "        for idx in diff_indices:\n",
    "            row = both.loc[idx]\n",
    "            rtrs = row['rtrs_control_number']\n",
    "            orig_val = row[orig_col]\n",
    "            new_val = row[new_col]\n",
    "            cusip = row.get('cusip_orig', row.get('cusip_new', 'N/A'))\n",
    "            \n",
    "            print(f\"RTRS: {rtrs}, CUSIP: {cusip}\")\n",
    "            \n",
    "            # Special formatting for arrays\n",
    "            if isinstance(orig_val, (list, np.ndarray)):\n",
    "                print(f\"  Original: array with shape {np.array(orig_val).shape}\")\n",
    "                print(f\"  New:      array with shape {np.array(new_val).shape}\")\n",
    "                # Show first few elements if they're arrays\n",
    "                try:\n",
    "                    orig_arr = np.array(orig_val)\n",
    "                    new_arr = np.array(new_val)\n",
    "                    if orig_arr.size > 0 and new_arr.size > 0:\n",
    "                        print(f\"    Original first element: {orig_arr.flat[0]}\")\n",
    "                        print(f\"    New first element: {new_arr.flat[0]}\")\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                print(f\"  Original: {orig_val}\")\n",
    "                print(f\"  New:      {new_val}\")\n",
    "            print()\n",
    "\n",
    "# Count total differences per row\n",
    "print(\"\\n\\nAnalyzing differences per row...\")\n",
    "base_cols = [col.replace('_orig', '').replace('_new', '') \n",
    "             for col in both.columns \n",
    "             if col.endswith('_orig')]\n",
    "\n",
    "diff_counts_per_row = []\n",
    "for idx, row in both.iterrows():\n",
    "    diff_count = 0\n",
    "    for col in base_cols:\n",
    "        if col != 'rtrs_control_number':\n",
    "            orig_col = f\"{col}_orig\"\n",
    "            new_col = f\"{col}_new\"\n",
    "            if orig_col in both.columns and new_col in both.columns:\n",
    "                if not safe_compare(row[orig_col], row[new_col]):\n",
    "                    diff_count += 1\n",
    "    diff_counts_per_row.append(diff_count)\n",
    "\n",
    "# Calculate statistics\n",
    "num_identical = sum(1 for count in diff_counts_per_row if count == 0)\n",
    "print(f\"\\nCompletely identical rows: {num_identical} out of {len(both)} ({(num_identical/len(both))*100:.1f}%)\")\n",
    "print(f\"Rows with at least one difference: {len(both) - num_identical}\")\n",
    "\n",
    "# Show distribution\n",
    "print(\"\\n\\nDistribution of differences per row:\")\n",
    "diff_series = pd.Series(diff_counts_per_row)\n",
    "print(diff_series.value_counts().sort_index().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
